\chapter{Implementation and Methodology}

The implementation of the DeepMD protocol employed in this thesis is based on
the DeepMD-kit software suite \cite{Wang_DeePMD-kit_A_deep_2018}. DeepMD-kit
uses TensorFlow \cite{tensorflow2015-whitepaper} to provide an efficient and
flexible toolkit for utilizing the DeepMD scheme. DeepMD-kit comes with an
interface to the LAMMPS classical molecular dynamics code \cite{LAMMPS},
which was used in this work for computing all the material properties with the
trained machine learning models. The models were trained on MD data generated
with OpenMX, DFT pseudo-potential code with a numerical atomic basis set.
\footnote{
    See \url{https://www.openmx-square.org/}
}. The Python programming language,
\footnote{
    See \url{https://www.python.org/}
} along with its multitude of scientific computation packages, was used for
building the training and evaluation infrastructure. All of the code needed to
reproduce the results presented in this thesis is available online
\footnote{
    See \url{https://github.com/hacksparr0w/bachelor-thesis}
}.

\section{Preparing the DFT Datasets}

As already stated, all AIMD trajectories were calculated using OpenMX. Since
the computation resources available for this work were quite limited, we
chose to only work with simple systems of pure silicon, as they do not
exhibit any complicated quantum mechanical effects and thus should be easier to model and
train on. To see how well the models perform on a wide variety of learning
data, three distinct datasets were prepared: an amorphous silicon dataset, a
crystalline silicon dataset, and a mixed dataset containing both the amorphous
and the crystalline frames. Each dataset contains a selection of frames taken
from OpenMX simulations of silicon systems with different volumes. After the
simulation frames were generated, they were further distilled down so as not
to include frames that were too similar to each other. This was done simply by
removing frames that were too close to each other in terms of their time step
(every 10th frame was selected). The detailed parameters for each used dataset
are listed in table \ref{tab:datasets}. The DFT training data consisted of
systems made of 100 atoms generated on a 3x3x3 $k$-grid (27 $k$-points) with
an energy cutoff of $250 \, \mathrm{Ry}$.

\begin{table}
  \begin{tabularx}{\textwidth}{lllll}
    \toprule
    \multicolumn{1}{c}{} & \multicolumn{2}{c}{Training} & \multicolumn{2}{c}{Validation} \\
    Dataset & Samples & Frames & Samples & Frames \\
    \midrule
    Crystalline & c-0.99 & 200 & c-1.01 & 200 \\
     & c-1.03 & 200 & & \\
    \midrule
    Amorphous & a-2.15 & 150 & a-2.25 & 150 \\
     & a-2.20 & 150 & a-2.31 & 150 \\
     & a-2.29 & 150 & & \\
     & a-2.30 & 150 & & \\
     & a-2.35 & 150 & & \\
     & a-2.40 & 150 & & \\
    \midrule
    Combined & c-0.99 & 200 & c-1.01 & 200 \\
     & c-1.03 & 200 & & \\
     & a-2.15 & 150 & a-2.25 & 150 \\
     & a-2.20 & 150 & a-2.31 & 150 \\
     & a-2.29 & 150 & & \\
     & a-2.30 & 150 & & \\
     & a-2.35 & 150 & & \\
     & a-2.40 & 150 & & \\
    \bottomrule
  \end{tabularx}
  \caption{The parameters used for the DFT datasets.}
  \label{tab:datasets}
\end{table}

\section{Choosing the DNN Hyperparameters}

DeepMD provides a bright palette of hyperparameters that can be used to
fine-tune the behavior of a DNN. The following is an excerpt from a sample DNN
training input:

\shorthandoff{-}
\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
  pipeTables,
  tableCaptions,
}
```
{
  "model": {
    "descriptor": {
      "type": "se_e2_a",
      "sel": [70],
      "rcut_smth": 1.8,
      "rcut": 6.0,
      "neuron": [5, 10, 20],
      "resnet_dt": false,
      "seed": 260222622
    },
    "fitting_net": {
      "neuron": [20, 20, 20],
      "resnet_dt": true,
      "seed": 260222622
    }
  },
  "learning_rate": {
    "type":"exp",
    "decay_steps": 20000,
    "start_lr": 0.001,
    "stop_lr": 1e-08
  },
  "loss": {
    "type": "ener",
    "start_pref_e": 1,
    "limit_pref_e": 500,
    "start_pref_f": 1000,
    "limit_pref_f": 10,
    "start_pref_v": 0,
    "limit_pref_v": 0
  },
  "training": {
    "numb_steps": 2000000,
    "seed": 10
  }
}
```
\end{markdown*}
\shorthandon{-}
\noindent Let's briefly discuss the most important configuration parameters
and their effect on the training and inference processes.

The \texttt{model} configuration section defines the architecture details of
a DNN. As per the definition in \eqref{eq:dnn}, the neural network is simply a
function of descriptors that predicts an energy value. The DeepMD
protocol implements this function as two separate neural networks,
where one is called the descriptor network and is defined by the
\texttt{model.descriptor} configuration section, and the other is called the
fitting network and is defined by the \texttt{model.fitting\_net}
configuration section. The descriptor network is fed with the descriptor data
as specified by the \texttt{model.descriptor.type} option, which makes it
possible to control whether the network uses the full radial and angular
information as per \eqref{eq:descriptor}. All of the models trained in this
work use full radial and angular information, so the
\texttt{model.descriptor.type} option is always set to \texttt{se\_e2\_a}.
The \texttt{model.descriptor.sel} option determines how many neighboring atoms
for a given atom type (indices correspond to the indices of the
\texttt{model.descriptor.type} option) are used for inference. The ideal value
for this option can be determined empirically from the training data using the
\texttt{dp neighbor-stat} utility that comes with the DeepMD-kit software.
This value was kept constant for all models in this work. The cutoff radius
specified by the \texttt{model.descriptor.rcut} and
\texttt{model.descriptor.rcut\_smth} options limits the radius of the local
environment constructed for each atom. The neighbors filtered with the
\texttt{model.descriptor.sel} option must be within the cutoff radius, which
is measured in \AA. The most important hyperparameters that have perhaps the
most significant effect on the quality of the model inference are
the \texttt{model.descriptor.neuron} and \texttt{model.fitting\_net.neuron}
options. These options specify the number of layers and the number of neurons
in each layer of the neural network. One of the difficulties of using deep neural
networks is coming up with good heuristics for driving the decisions on the
appropriate network architectures. A great portion of
\autoref{chap:results-and-evaluation} focuses on choosing and evaluating
various network architectures. When training the models, it is important to
choose a random seed that is used by the internal pseudo-random number
generator to initialize the weights and biases of the neural network. This is
very important for two reasons. Firstly, we can ensure the reproducibility of
training results by using the same seeds. Secondly, we can use multiple
models with different seeds and calculate inference uncertainties based on
their inference results, which will differ the more uncertain the models
are. A comparison of models with different seeds is also discussed in later
chapters.

Another important configuration section is the \texttt{learning\_rate}
section. It implements the learning rate function as per
\eqref{eq:learning-rate}. The values of this configuration were optimized to
go along with the empirically chosen number of training steps
(the \texttt{training.numb\_steps} option) and do not differ on a per-model
basis.

Last but not least, the \texttt{loss} configuration section defines the
behavior of the loss function by varying the loss prefactors defined in
\eqref{eq:loss-weight}. In our case, the loss function is set so that it
aggressively optimizes for the force predictions at the beginning of the
training process and then gradually shifts the focus to the energy
predictions.

The whole training matrix of models used in this work is available in table
\ref{tab:models}. All of the trained models were evaluated using the
\texttt{dp test} utility ran on one of the systems from the validation
dataset.

\begin{table}
  \begin{tabularx}{\textwidth}{llll}
    \toprule
    Dataset & Descriptor Neurons & Fitting Neurons & Seed \\
    \midrule
    Amorphous & [5, 10, 20] & [20, 20, 20] & 260222622 \\
     & [10, 20, 40] & [10, 10, 10] & 260222622 \\
     & & [20, 20, 20] & 260222622 \\
     & & [50, 50, 50] & 260222622 \\
     & & [75, 75, 75] & 260222622 \\
     & [25, 50, 100] & [20, 20, 20] & 260222622 \\
    \midrule
    Crystalline & [5, 10, 20] & [20, 20, 20] & 260222622 \\
     & [10, 20, 40] & [10, 10, 10] & 260222622 \\
     & & [20, 20, 20] & 260222622 \\
     & & & 537693349 \\
     & & & 836424474 \\
     & & [50, 50, 50] & 260222622 \\
     & & [75, 75, 75] & 260222622 \\
     & [25, 50, 100] & [20, 20, 20] & 260222622 \\
    \bottomrule
    Combined & [5, 10, 20] & [20, 20, 20] & 260222622 \\
     & [10, 20, 40] & [10, 10, 10] & 260222622 \\
     & & [20, 20, 20] & 260222622 \\
     & & [50, 50, 50] & 260222622 \\
     & & [75, 75, 75] & 260222622 \\
     & [25, 50, 100] & [20, 20, 20] & 260222622 \\
  \end{tabularx}
  \caption{The table of all trained models with their hyperparameters.}
  \label{tab:models}
\end{table}

\section{Computing Material Properties}

This work focuses not only on the training of the DNN models but also on
the evaluation of their inference performance. To evaluate the inference
performance, we chose to compute the relaxation volume $V_0$ and the bulk
modulus $B_{T_0}$ \eqref{eqn:bulk-modulus} of both crystalline and amorphous
Si structures. The volumetric thermal expansion coefficient $\alpha_V$ was
also computed in the case of amorphous Si. It is defined as
\begin{equation}
  \alpha_V = \frac{1}{V} \left( \frac{\partial V}{\partial T} \right)_p,
\end{equation}
where $V$ is the volume of the system, $T$ is the temperature, and $p$ is the
pressure.

To calculate these material properties, we use LAMMPS with the trained models
to perform a series of simulations and then fit the measured data to the
Birch--Murnaghan EOS \eqref{eqn:birch-murnaghan-energy} model. For the
crystalline Si materials, we initialize a LAMMPS simulation with a diamond Si
supercell with a side length of $543 \, \mathrm{\AA}$ and a lattice constant
of $5.43 \, \mathrm{\AA}$. We then perform a deformation under the NVE
ensemble within 500 simulation steps and let LAMMPS minimize the energy of the
resultant configuration. A default timestep of $0.001 \, \mathrm{ps}$ is used
in this case. The amorphous Si materials are generated using the melt-quench
method. In this scenario, we randomly generate 100 Si atoms in a cubic box so
that the density of the system is $2.33 \, \mathrm{g/cm^3}$. We then heat the
system up to $4000 \, \mathrm{K}$ using the NPT ensemble with a constant
pressure of $0 \, \mathrm{Pa}$ in $1 \cdot 10^{6}$ steps. The same ensemble is
then used to cool the system down to $0 \, \mathrm{K}$ in $50 \cdot 10^{6}$
steps. It is of the utmost importance to use a sufficiently large number of
steps to ensure the system is properly equilibrated and can be used in further
simulations. The timestep in this case is set to $0.0005 \, \mathrm{ps}$. The
amorphous Si structures are generated using an OpenKIM interatomic potential
and not any of the trained DeepMD potentials. To compute the material
properties, we then perform a very similar simulation to the one used for
crystalline Si, but we use the NVT ensemble instead of the NVE ensemble to get
the system to the desired temperature. The LAMMPS input scripts used for the
simulations are available in the mentioned repository.

To estimate the measurement uncertainty of the computed material properties,
we compute the properties using multiple models with the same architecture
but different seeds and then calculate the mean and standard deviation of the
results. This was done only for the crystalline Si models, where the material
properties were computed at $0 \, \mathrm{K}$. Material properties of
amorphous Si were computed at various different temperatures, and it would be
too time-consuming to compute them using multiple models.
