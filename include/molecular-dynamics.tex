\chapter{Molecular Dynamics}

Molecular dynamics simulations is an umbrella term for a class of
computational methods used to model and analyze the physical behavior of
systems of atoms and molecules. MD allows one to monitor the full time
evolution of a system, allowing for deep examination of the dynamics of
atomic-level phenomena that cannot be observed directly.
Computer simulations applied to condensed matter systems began their
development as early as the 1950s, when two of the pillars of molecular
simulation were introduced, namely the Monte Carlo (MC) sampling technique and
the molecular dynamics method. In 1964, the first realistic MD simulation was
developed by Rahman, who came up with a realistic model of liquid Argon.
Rahman used the Lennard–Jones pair-wise additive potential and showed, that
MD simulations with smooth potentials were possible.

Around the same time, Verlet proposed a stable numerical integration
algorithm that is still very popular in modern MD software. We will discuss
the Verlet integration algorithm in further chapters of this thesis. Verlet
also invented a time-saving algorithm, the Verlet neighbour list.

A great leap forward in the MD methology happened in 1971, when Rahman and
Stillinger published an MD study on modeling a realistic system of liquid
water, a system composed of molecules, not just individual atoms. The
significant results of their work prompted a multinational group of scientists
centred around Berendsen at CECAM to try using MD simulations for examining
biomolecules. The first MD simulation of a simple protein was due to Karplus
and collaborators, and appeared shortly after, in 1977. In 2013, the Nobel
Prize for Chemistry was awarded to Warshel, Levitt, and Karplus for their work
on computer simulations in biochemistry, which was built upon the efforts of
many researchers who had previously worked on simulating biomolecules.

Another inportant development took place in 1980. In this year, Anderson
published a paper that described how to extend MD to enable it to sample the
isoenthalpic (constant pressure) ensemble. The standard molecular dynamics
algorithm was designed to simulate the behavior of a system of particles at
constant energy, or in the microcanonical ensemble, because the Newton's
equations of motion conserve energy. It was not straightforward to modify the
MD algorithm to sample systems under different, more experimentally relevant
conditions. Andersen's extensions for sampling the isoenthalpic ensemble
inspired the question of whether it was possible to use MD to sample the
canonical ensemble as well. Nosé, building on Andersen's work, introduced a
new variable that linked the kinetic energy of the atoms to the external
temperature, resulting in dynamics that sample the desired ensemble. This
approach is known as the Nosé–Hoover thermostat, which is often used in a
modified form called the Hoover thermostat.

In 1985, Car and Parrinello published a groundbreaking paper in Physical
Review Letters that described a method for combining MD with density
functional theory (DFT) calculations of electronic structure. This approach
eliminated the need for a potential model, as energy, forces, and stress
could be calculated directly from the electronic structure. The Car–Parrinello
method allowed for the simulation of processes that involve bond formation or
breaking and was the first to demonstrate that it is possible to combine
finite temperature simulations with ground-state electronic structure
calculations. This method also served as a bridge between the simulation
community, which typically has a background in statistical mechanics, and the
solid-state physics and quantum chemistry communities, which focus on
electronic structure calculations at zero temperature.

During the 1980s and 1990s, the use of molecular simulations in condensed
matter research became more widespread, due in part to previous successes in
this field and also to the increasing availability and power of computers.

Modern MD methodology is frequently used to refine the three-dimensional
structures of proteins and other large molecules, to study atomic-level
phenomena that cannot be directly observed, such as thin-film growth and ion
implantation, and to investigate the physical properties of nanotechnological
devices that cannot yet be manufactured. In 2015, for example, MD simulation
has been reported for pharmacophore development and drug design.

\subsection{Classical Methods}

The classical MD implementation uses the so-called "ball and sticks" model,
where atoms and molecules are treated as soft balls and their bonds are
represented by elastic sticks. The laws of classical mechanics define the
dynamics of the entire system.

Each particle in an MD simulation has its own position vector
$\mathbf{r}_i(t) = (x_i(t), y_i(t), z_i(t))$. A particle usually corresponds
to an atom, although it may represent any simulable entity of interest that
can be conveniently described by an interaction law. By Newton's second law
the motion of each particle must obey the following relation

\begin{equation}
  \mathbf{F}_i = m_i \diff[2]{\mathbf{r}_i}{t},
\end{equation}

\noindent where $m_i$ is the mass of $i$-th particle and $\mathbf{F}_i$ is the
force acting upon $i$-th particle. Interaction laws are usually specified by
a potential function $U(\mathbf{r}_1, \dots, \mathbf{r}_N)$, which represents
the potential energy of $N$ interacting particles as a function of their
positions. Given the potential, the force acting upon $i$-th atom is
determined by the gradient with respect to particle displacements

\begin{equation}
  \mathbf{F}_i = - \nabla_{\mathbf{r}_i} U(\mathbf{r}_1, \dots, \mathbf{r}_N)
  = - \left(
    \frac{\partial U}{\partial x_i},
    \frac{\partial U}{\partial y_i},
    \frac{\partial U}{\partial z_i}
  \right).
\end{equation}

\noindent Let's briefly talk about the meaning and form of the potential $U$
in MD simulations. Any quantum-chemistry textbook would insist, that in order
to appropriately examine a behavior of molecule, we can't just look at its
individual atoms. The quantum-mechanical lense reveals, that when atoms bond
into molecules, their electron orbitals interact in complex ways, giving rise
to non-trivial molecule orbitals. These electronic clouds that span multiple
atoms then determine molecule's interactions with other particles. This paints
molecules as a very complicated quantum systems, where electrons and nuclei
are interacting together in an intricate manner. It turns out, however, that
to a very good approximation, known as the Born–Oppenheimer adiabatic
approximation and based on the difference in mass between nuclei and
electrons, the electronic and nuclear problems can be separated. According to
this approximation, we can presume that the electron clouds equilibrate
quickly for each instanteneous configuration of the heavy nuclei. The nuclei
then move in the field created by the average electron densities.
This allows us to consider the concept of a potential energy surface, which
controls the movement of the nuclei without taking explicit account of the
electrons. Given the potential energy surface, we may use classical mechanics
to follow the dynamics of the nuclei. Rather than solving the
quantum-mechanical problem, we can solve a classic-mechanical problem, in
which the effect of the electrons on nuclei is expressed by en empirical
potential. It can be very challenging to identify a potential function that
accurately represents an energy surfaces of a system, but doing so greatly
simplifies the computational process. Atomic force field models and the
classical MD are based on empirical potentials with a specific functional
form, representing the physics and chemistry of the systems of
interest. The following equation is an example of such a force field, used in
biosystem simulations

%
% TODO: Include a brief discussion of MD limitations, scaling, etc.
%

\begin{equation}
\begin{alignedat}{2}
  U(\mathbf{r}_1, \dots, \mathbf{r}_N) = &
  \sum_\text{bonds} \frac{a_i}{2} (l_i - l_{i0})^2
  + \sum_\text{angles} \frac{b_i}{2} (\theta_i - \theta_{i0})^2 \\
  &+ \sum_\text{torsions} \frac{c_i}{2} \left[
    1 + \cos(n \omega_i - \gamma_i)
  \right] \\
  &+ \sum_\text{atom pairs} 4 \varepsilon_{ij} \left[
    \left(\frac{\sigma_{ij}}{r_{ij}}\right)^{12}
    - \left(\frac{\sigma_{ij}}{r_{ij}}\right)^{6}
  \right] \\
  &+ \sum_\text{atom pairs} k \frac{q_i q_j}{r_{ij}}.
\end{alignedat}
\end{equation}

The covalent character of the system is defined by the first three terms of
the system, where the summation indices run over all the bonds, angles and
torsions. In contrast, the last two terms are only defined by atom pairs,
with $q_i q_j$ being the product of their charges and $r_{ij} = |r_i - r_j|$
is the distance between the two atoms in the pair. The first two terms give
energies of deformations of the bond lengths $l_i$ and bond angles $\theta_i$
from their respective equilibrium values $l_{i0}$ and $\theta_{i0}$ with force
constants $a_i$ and $b_i$. These two terms model the correct chemical
structure, but prevent more complicated chemical phenomena like bond breaking.
Rotations around the chemical bond are described by the third therm, which is
priodic with periodicity determined by $n$ and heights of rotational barriers
defined by $c_i$. The forth term represents the van der Waals repulsive and
attractive interatomic forces in the form of the Lennard–Jones 12-6 potential.
The last term is the Coulomb electrostatic potential. Some effects due to
specific environments can be accounted for by properly adjusting partial
charges $q_i$ and effective value of the constant $k$ as well as the van der
Waals parameters $\varepsilon_{ij}$ and $\sigma_{ij}$.

We now have a full mathematical description of the problem at hand. Due to the
many-body nature of the problem, it is out of question to solve it
analytically, thus it has to be discretized and solved numerically with a
computer. First, we need to specify the initial conditions of the system,
that is, the initial positions $\mathbf{r}_{i0}$ and initial velocities
$\mathbf{v}_{i0}$ of the particles in the system. Then we have to use a
numerical integrator to continually make finite time interval steps and find
the successive values of positions $\mathbf{r}_i(t)$ and velocities
$\mathbf{v}_{i}(t)$ in the time evolution of the system.

\subsection{\textit{Ab Initio} Methods}



\subsection{Density Functional Theory}



\subsection{Machine Learning}



\subsection{Deep Potential Molecular Dynamics}

The Deep Potential Molecular Dynamics (DeepMD) \parencite{Zhang_2018} method
uses neural networks for modeling many-body potentials and interatomic forces
to drive classical molecular dynamics. The neural network architectures used
by the DeepMD method are designed so that they preserve all the natural
symmetries in the problem. These models are trained on \textit{ab initio} data
and are capable of producing results that are essentially indistinguishable
from the original data while scaling linearly with the system size.

One of the most notable challenges in developing an efficient NN schema for
molecular dynamics is devising an input format that would preserve the
translational, rotational, and permutational symmetry of the system. The raw
atomic coordinates from MD simulations cannot be used directly, as they do not
exhibit these symmetries. Different ML models were proposed to address this
problem. For example, the Behler--Parrinello neural network (BPNN)
\parencite{PhysRevLett.98.146401} maps the coordinates onto a large set of
two- and three-body symmetry functions. Another proposed model,
gradient-domain machine learning (GDML)
\parencite{doi:10.1126/sciadv.1603015}, maps the coordinates onto the
eigenvalues of the Coulomb matrix. Both of these protocols are successful, but
they are also needlessly complicated, with their use-cases being rather
limited, as they do not come from a first-principles analysis of the modeling
problem, and it is not straightforward to extend them beyond simple systems.
The DeepMD methodology attempts to provide a more first principle-based
approach to overcome the limitations associated with auxiliary quantities like
the symmetry functions or the Coulomb matrix.

Consider a system of $N$ atoms, where the coordinates of these atoms can be
represented as a set of position vectors
$\{\mathbf{R}_1, \dots, \mathbf{R}_N\}$, with each
$\mathbf{R}_i \in \mathbb{R}^3$. DeepMD decomposes the total system energy $E$
into a sum of energy contributions from individual atoms,
\begin{equation}
  E = \sum_i^N E_i,
\end{equation}
where $i$ is an index of an individual atom. Atomic energy $E_i$ is fully
determined by the position of the $i$th atom and by the positions of its near
neighbours,
\begin{equation}
  E_i = E_{s(i)}(\mathbf{R}_i, \{\mathbf{R}_j \mid j \in  N_{R_C}(i)\}),
\end{equation}
where $N_{R_C}(i)$ denotes the index set of the neighbour atoms of atom $i$
within the cut-off radius $R_C$. $s(i)$ is the chemical species of atom $i$.
For reasons discussed above, it is less than optimal to use the position
vector data $\mathbf{R}_i, \{\mathbf{R}_j \mid j \in  N_{R_C}(i)\}$ when
modeling the function $E_{s(i)}$ with DNN. Thus, the DeepMD method introduces
a mapping from position vectors to "descriptors" of atomic chemical
environment, that better capture the underlying symmetries.

To construct the descriptor for atom $i$, we first calculate the relative
positions of its neighbouring atoms,
\begin{equation}
  \mathbf{R}_{ij} = \mathbf{R}_j - \mathbf{R}_i.
\end{equation}
The coordinate of the relative position $R_{ij}$ under the lab reference frame
$\{\mathbf{e}_x^0, \mathbf{e}_y^0, \mathbf{e}_z^0\}$ is denoted by
$(x_{ij}^0, y_{ij}^0, z_{ij}^0)$, such that
\begin{equation}
  \mathbf{R}_{ij} = x_{ij}^0 \mathbf{e}_x^0 + y_{ij}^0 \mathbf{e}_y^0
    + z_{ij}^0 \mathbf{e}_z^0.
\end{equation}
Both representations $\mathbf{R}_{ij}$ and $(x_{ij}^0, y_{ij}^0, z_{ij}^0)$
preserve the translational symmetry. The rotational symmetry is captured by
constructing a local frame of reference and using it to express the
coordinates of neighbouring atoms. We first pick atoms with indices $a(i)$ and
$b(i)$ from the neighbours $N_{R_C}(i)$ by certain user-specified rules. The
local reference frame $\{\mathbf{e}_{i1}, \mathbf{e}_{i2}, \mathbf{e}_{i3} \}$
of atom $i$ is then constructed by
\begin{align}
  \mathbf{e}_{i1} = \mathbf{e}(\mathbf{R}_{ia(i)}), \\
  \mathbf{e}_{i2} = \mathbf{e}\left(
    \mathbf{R}_{ib(i)} -
    (\mathbf{R}_{i b(i)} \cdot \mathbf{e}_{i1}) \mathbf{e}_{i1}
  \right), \\
  \mathbf{e}_{i3} = \mathbf{e}_{i1} \times \mathbf{e}_{i2},
\end{align}
where $\mathbf{e}(\mathbf{R})$ denotes the normalized vector of $\mathbf{R}$,
such that $\mathbf{e}(\mathbf{R}) = \mathbf{R} / |\mathbf{R}|$. The local
coordinate $(x_{ij}, y_{ij}, z_{ij})$ is then calculated from the lab
coordinate $(x_{ij}^0, y_{ij}^0, z_{ij}^0)$ through the transformation
\begin{equation}
  (x_{ij}, y_{ij}, z_{ij}) = (x_{ij}^0, y_{ij}^0, z_{ij}^0) \cdot
    \mathcal{R}(\mathbf{R}_{i a(i)}, \mathbf{R}_{i b(i)}),
\end{equation}
where
\begin{equation}
  \mathcal{R}(\mathbf{R}_{i a(i)}, \mathbf{R}_{i b(i)}) =
    [\mathbf{e}_{i1}, \mathbf{e}_{i2}, \mathbf{e}_{i3}]
\end{equation}
is the rotation matrix with the columns being the local reference frame
vectors. The descriptive information of atom $i$ given by neighboring atom $j$
is then obtained by using either both the radial and angular information or
only the radial information
\begin{equation}
  \{D_{ij}\} = \begin{cases}
    \left\{
      \frac{1}{R_{ij}},
      \frac{x_{ij}}{R_{ij}},
      \frac{y_{ij}}{R_{ij}},
      \frac{z_{ij}}{R_{ij}}
    \right\}, & \text{full information;} \\
    \left\{\frac{1}{R_{ij}}\right\}, & \text{radial-only information.}
  \end{cases}
\end{equation}
The order of the neighbour indices $j$ in $\{D_{ij}\}$ is fixed by sorting
them first by their chemical species and then, within each chemical species,
according to their inverse distances to the atom $i$, i.e., $1/R_{ij}$. The
permutational symmetry is naturally preserved in this way. This is the full
procedure for constructing the mapping from atomic positions to descriptors,
which is denoted by
\begin{equation}
  \mathbf{D}_i = \mathbf{D}_i(
    \mathbf{R}_i, \{\mathbf{R}_j \mid j \in  N_{R_C}(i)\}
  ).
\end{equation}
The descriptors $\mathbf{D}_i$ preserve the translational, rotational, and
permutational symmetries and are passed to a DNN to evaluate the atomic
energies. This process can be mathematically expressed as
\begin{equation}
  E_{s(i)} = \mathcal{N}_{s(i)}(\mathbf{D}_{i}),
\end{equation}
The DNN used by DeepMD method is a feed forward neural network with multiple
hidden layers, where each layer transforms the input data $\mathbf{d}_i^{p-1}$
from the previous layer into $\mathbf{d}_i^{p}$ and passes them as an input
to the next layer. The transformation consists of a linear and a non-linear
step, i.e.
\begin{equation}
  \mathbf{d}_{i}^{p} = \varphi \left(
    \mathbf{W}_{s(i)}^p \mathbf{d}_i^{p-1} + \mathbf{b}^p_{s(i)}
  \right),
\end{equation}
where $\varphi$ represents the non-linear function and $\mathbf{W}_{s(i)}^p$
and $\mathbf{b}^p_{s(i)}$ are free parameters of the linear transformation to
be optimize by the training process.
