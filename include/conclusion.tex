\chapter{Conclusion}

This work used the DeepMD methodology to demonstrate the viability and
efficiency of machine learning potentials for performing molecular dynamics
and calculating the material properties of both crystalline and amorphous
materials. We have trained a wide variety of DNN models to show how
hyperparameter selection affects their inference accuracy. We then used the
best-performing models to perform molecular dynamics simulations of crystalline and amorphous silicon. Subsequently, we
used the data from the molecular dynamics simulations to compute the
equilibrium volume $V_0$, the bulk modulus $B_0$, and the volumetric thermal
expansion coefficient $\alpha_V$ of silicon. The results from the machine
learning models were very promising and showed that we can get quite accurate
results with relative errors of $\sim 0.3\%$ for the relaxation volume $V_0$
of crystalline silicon, and $\sim 17 \%$ for the bulk modulus $B_0$ of crystalline
silicon when comparing to other third-party DFT calculations. A significantly
worse performance was observed for amorphous silicon, where the relative error
was compared to experimental data, with $\sim 90 \%$ error for the bulk modulus.
It was noted that our modeled data is too noisy for calculating the volumetric
thermal expansion coefficient $\alpha_V$ of amorphous silicon, but we believe that this
was mostly due to the shortcomings of the specific settings of our methodology
caused by a lack of computational resources and time, not by the inherent conceptual flaws in
the DNN modeling approach. We note that the accuracy of the results can be
drastically improved by using larger atomic systems and bigger training data sets,
and that the quality and size of the training data sets are the most important factors limiting the
model prediction accuracy. We also note that this may be quite problematic as
quality training data can only be obtained with computationally expensive
quantum mechanical simulations, which is the main bottleneck for the DeepMD
methodology.

Future work should focus on improving the quality of the training data sets,
making use of methodologies for generating training data on the fly (e.g., by
using the active learning approach), comparing the DeepMD methodology with
alternative machine learning implementations, or accelerating the current DeepMD
protocol presented in this work by moving to GPU-based learning and inference.
